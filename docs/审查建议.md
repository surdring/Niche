kiro针对 Study Copilot 的补充建议:
1. 多模态必须是 Day 1 能力
当前 
study-copilot-template.md
 的 Tool Schema 都是纯文本输入（questionText: z.string()）。需要改成：

const QuestionInput = z.object({
  // 二选一：文本或图片
  questionText: z.string().optional(),
  questionImage: z.string().optional(), // base64 或 URL
  // 至少有一个
}).refine(data => data.questionText || data.questionImage, {
  message: "必须提供题目文本或图片"
});
技术上，GPT-4o / Claude 3.5 Sonnet 的视觉能力已经足够识别手写/印刷的数学题。

2. 错题记忆的存储设计
审查中提到：

WeeklyReview 功能依赖于对历史数据的聚合。需要在后端实现中明确这一块的逻辑。

建议的数据模型：

// 每次错题分析后持久化
interface WrongQuestionRecord {
  id: string;
  tenantId: string; // 预埋
  userId: string;
  subject: Subject;
  
  // 原始输入
  questionText?: string;
  questionImageUrl?: string;
  userSolution: string;
  
  // 分析结果（直接存 LLM 输出）
  analysis: AnalyzeWrongQuestionOutput;
  
  // 用于聚合
  knowledgePoints: string[];
  errorType: ErrorType;
  
  createdAt: Date;
}
这样 WeeklyReview 就是一个简单的 SQL 聚合：

SELECT knowledge_point, error_type, COUNT(*) 
FROM wrong_questions 
WHERE user_id = ? AND created_at > ?
GROUP BY knowledge_point, error_type
3. 学术诚信的实现细节
当前文档只说了"检测到作业场景时拒绝给答案"，但没说怎么检测。

建议在 wrapLanguageModel 中间件中实现：

const homeworkPatterns = [
  /作业/,
  /明天.*交/,
  /考试.*题/,
  /帮我.*做/,
  /直接.*答案/,
];

function detectHomeworkIntent(input: string): boolean {
  return homeworkPatterns.some(p => p.test(input));
}
检测到后，强制注入 System Prompt 后缀：

【重要】检测到这可能是正在进行的作业/考试。
你只能：1) 给出解题思路提示 2) 指出用户解法中的错误
你不能：直接给出完整答案或可抄写的解题过程
4. 关于 RAGFlow 的务实建议
审查中提到 RAGFlow 的坐标定位风险。对于 Study Copilot，我的建议是：

短期不接 RAGFlow。

原因：

高考知识点是相对固定的，大模型内置知识已经足够
错题复盘、练习生成这些场景不需要检索外部文档
接入教材 PDF 的 ROI 不高（教材内容模型都知道）
什么时候需要 RAG：

如果你想接入学校的内部题库/模拟卷
如果你想做"根据教材某一页讲解"的功能
这些可以放到后期。

5. 一个更完整的功能优先级
| 优先级 | 功能 | 为什么重要 | |--------|------|-----------| | P0 | 图片输入 + OCR/视觉理解 | 没有这个，产品不可用 | | P0 | 错题复盘（含错因分析） | 核心价值 | | P0 | 错题记录持久化 | 为周度总结打基础 | | P1 | 知识点讲解 | 高频需求 | | P1 | 巩固练习生成 | 高频需求 | | P1 | 学术诚信检测 | 合规必须 | | P2 | 写作反馈 | 语文/英语场景 | | P2 | 周度总结 + 练习计划 | 需要数据积累 | | P3 | 接入教材/题库 RAG | 锦上添花 |


----------------------------------------


gemini对这三份文档（需求文档、Study Copilot 规格说明、Roadmap）的详细审查和分析。

---

### 1. 总体评价

*   **架构清晰，边界明确**：明确区分了“核心架构”（Provider 接口、Zod 结构化、流式协议）与“场景业务”（模板、RAG 资料处理）。
*   **技术选型现代且务实**：选择 Vercel AI SDK Core + Fastify + GraphQL 是高性能与开发体验的最佳平衡。利用 RAGFlow 处理复杂的 ETL（文档解析/分块），让自己专注于编排和交互，避免了重复造轮子。
*   **产品价值观鲜明**：特别是在教育场景（Study Copilot）中强调 "Explain & Verify" 而非直接给出答案，这在当前 AI 教育产品中是一个非常重要的差异化和合规点。
*   **工程化思维强**：
    *   预埋 `tenantId` 以备未来的多租户扩展（Req 29）。
    *   强制 Zod Schema 校验以确保 LLM 输出的可用性（Req 22）。
    *   详细定义的流式事件协议（Req 38 中的 Bootstrap events）。

---

### 2. 文档详细审查

#### A. 需求文档 (`requirements.md`)

这是核心文档，质量很高。

**亮点：**
*   **Req 22 (Zod 结构化输出)**：这是构建 Agent 的基石。强调 "Partial JSON Parsing" 对提升流式响应的用户体验至关重要。
*   **Req 28 (强引用模式)**：针对“幻觉”问题的终极杀手锏。设计了 `answerPolicy` (strict/force)，兼顾了严谨性和可用性。
*   **Req 38 (Bootstrap 起步包)**：这是一个非常惊艳的 Feature。不仅仅是“对话”，而是“自动化的预研工作流”（生成问题树 -> 搜索 -> 下载 -> 待办），极大地提升了用户获得感。
*   **Req 16 (GraphQL & API)**：选择 GraphQL 作为主干非常适合这种复杂的、图状的数据结构（Project -> Sources -> Claims -> Citations）。

**潜在风险与建议：**
*   **Req 30 (RAGFlow 契约)**：依赖外部 RAG 服务进行“页码级/坐标级”定位（Req 33）风险较高。PDF 解析极其复杂，如果 RAGFlow 对某些文档解析丢失了坐标信息，前端的高亮功能会直接失效。
    *   *建议*：在实现层增加一个“降级渲染器”，当坐标缺失时，能优雅地退化为显示文本片段匹配或仅显示页码。
*   **Req 37 (本地模型)**：本地小参数模型（如 Llama-3-8B 等）在遵循复杂的 Zod Schema 和 Tool Calling 时往往表现不佳。
    *   *建议*：在本地模型适配层，强制开启 `json_mode` 或使用 Grammar Sampling（llama.cpp 支持 GBNF）来物理约束输出格式，而不仅仅依赖 Prompt。

#### B. 场景模板：Study Copilot (`specs/study-copilot.md`)

这份文档很好地展示了 Niche 如何通过“模板”来定义垂直业务。

**亮点：**
*   **反作弊机制**：明确的 System Prompt 策略，检测到 "homework" 上下文时拒绝直接给答案。这是进入学校/家庭场景的入场券。
*   **交互模式设计**：摒弃了单一的 Chat 框，设计了“按钮式追问”（给我提示、一步步带我做），这非常符合教育心理学中的“脚手架”理论。
*   **数据结构设计**：Tool 的 Input/Output Schema 定义得非常具体（如 `AnalyzeWrongQuestionOutput` 中的 `errorType` 枚举），便于后续的数据分析和报表生成。

**建议：**
*   **上下文窗口管理**：高中题目（尤其是理科）往往包含复杂的公式甚至图形描述。如果单纯依赖文本/LaTeX，模型理解力有限。
    *   *建议*：虽然文档提到了多模态（Req 12），但在 Study Copilot 中应将其列为 P0 级能力（即支持上传题目图片进行 OCR 或视觉理解）。
*   **记忆持久化**：`WeeklyReview` 功能依赖于对历史数据的聚合。这不仅仅是 LLM 的任务，更是数据库层面的聚合查询任务。需要在后端实现中明确这一块的逻辑（是实时分析所有 Log，还是每天生成摘要存下来）。

#### C. Roadmap (`roadmap.md`)

规划合理，分阶段实施策略稳健。

**亮点：**
*   **以 Research Copilot 为旗舰**：集中火力打穿一个高难度场景（长文档、引用、工作流），能够验证框架的极限能力。
*   **基础设施先行**：Phase 1 先搞定 RAGFlow 和本地推理的连通性，这是非常务实的做法。

**建议：**
*   **关于 Eval 的优先级**：目前 Eval 在中期规划中。实际上，对于 Research Copilot 这种强调“准确性”和“引用”的场景，早期的 Eval（哪怕是简单的单元测试 + 人工评分）非常重要，否则很难优化 Prompt。建议在短期规划中加入最基础的自动化测试（例如：确保生成的 JSON 总是符合 Schema）。

---

### 3. 关键技术难点预判

根据文档，实施过程中最大的技术挑战可能在于以下几点：

1.  **PDF 深度解析与坐标对齐 (Deep Parsing)**：
    *   **问题**：从 PDF 提取文本并保持阅读顺序（双栏、页眉页脚去除）已经很难，还要返回精确的 Bounding Box 用于前端高亮。
    *   **对策**：需要深度定制 RAGFlow 的配置，或者在 Niche 层做二次处理。如果 RAGFlow 返回的 chunk 不带坐标，可能需要回溯原始文档进行模糊匹配定位。

2.  **长文档的上下文管理**：
    *   **问题**：Research Copilot 可能会摄入整本书。即使有 RAG，跨章节的推理也很难。
    *   **对策**：Req 31 提到的 Map-Reduce 策略（分段总结）必须落地。

3.  **流式传输的复杂性**：
    *   **问题**：Bootstrap 过程包含多个阶段（Plan -> Search -> Download -> Ingest），这是一个耗时很长的异步过程，但前端需要实时反馈。
    *   **对策**：Req 38 定义的 `progress events` 协议至关重要。实现时，可能需要结合 Server-Sent Events (SSE) 或者 GraphQL Subscription。需注意 HTTP 连接超时问题。

### 4. 总结

这是一套**可以直接进入开发阶段**的高质量需求文档。

*   **产品定义**：清晰，切中痛点（可控、可追溯、防幻觉）。
*   **技术架构**：先进，具备良好的扩展性（Plugin/Template 机制）。
*   **执行路径**：Roadmap 具有极高的可操作性。

**下一步行动建议：**
1.  **冻结 API 契约**：根据 Req 38 和 Study Copilot Spec，确定 GraphQL Schema 和流式事件的具体 JSON 结构。
2.  **RAGFlow 原型验证**：立即着手验证 RAGFlow 对复杂 PDF 的解析能力，确认是否能满足“引用高亮”的数据需求，这决定了 Research Copilot 的体验上限。
3.  **启动开发**：按照 Roadmap Phase 1 开始搭建脚手架。